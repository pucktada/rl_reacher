{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-25T03:54:10.203781Z",
     "start_time": "2019-10-25T03:54:08.694764Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2931e360f50>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "import numpy as np\n",
    "import time\n",
    "import random\n",
    "import torch\n",
    "from ddpg import Agent\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "seed = 0\n",
    "\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment\n",
    "\n",
    "In this environment, a double-jointed arm can move to target locations. A reward of +0.1 is provided for each step that the agent's hand is in the goal location. Thus, the goal of your agent is to maintain its position at the target location for as many time steps as possible.\n",
    "\n",
    "The observation space consists of 33 variables corresponding to position, rotation, velocity, and angular velocities of the arm. Each action is a vector with four numbers, corresponding to torque applicable to two joints. Every entry in the action vector must be a number between -1 and 1.\n",
    "\n",
    "We are doing the 2nd version of the project, which contains 20 identical agents, each with its own copy of the environment.\n",
    "\n",
    "Run the code cell below to print some information about the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-25T03:54:14.688834Z",
     "start_time": "2019-10-25T03:54:10.318784Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\tgoal_speed -> 1.0\n",
      "\t\tgoal_size -> 5.0\n",
      "Unity brain name: ReacherBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 33\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 20\n",
      "Size of each action: 4\n",
      "There are 20 agents. Each observes a state with length: 33\n",
      "The state for the first agent looks like: [ 0.00000000e+00 -4.00000000e+00  0.00000000e+00  1.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -4.37113883e-08  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00 -1.00000000e+01  0.00000000e+00\n",
      "  1.00000000e+00 -0.00000000e+00 -0.00000000e+00 -4.37113883e-08\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  5.75471878e+00 -1.00000000e+00\n",
      "  5.55726624e+00  0.00000000e+00  1.00000000e+00  0.00000000e+00\n",
      " -1.68164849e-01]\n"
     ]
    }
   ],
   "source": [
    "env = UnityEnvironment(file_name='Reacher_Windows_x86_64/Reacher.exe')\n",
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]\n",
    "\n",
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents\n",
    "num_agents = len(env_info.agents)\n",
    "print('Number of agents:', num_agents)\n",
    "\n",
    "# size of each action\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Size of each action:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "states = env_info.vector_observations\n",
    "state_size = states.shape[1]\n",
    "print('There are {} agents. Each observes a state with length: {}'.format(states.shape[0], state_size))\n",
    "print('The state for the first agent looks like:', states[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RL Agent & Model\n",
    "\n",
    "### Model\n",
    "model: ddpg/model.py\n",
    "model.py contains two neural network model, a actor network and a critic network. \n",
    "\n",
    "#### The actor network\n",
    "The actor network is a 3-layers fully-connected neural network of size (400x300x4) with a batch normalization layer. The actor network takes a state (of size 33) and output an action. \n",
    "\n",
    "#### The critic network\n",
    "The critic network is a 3-layers fully-connected neural network of size (400x(300+4)x1) with a batch normalization layer. The critic network takes a state 's' (of size 33) and an action 'a' (of size 4) and approximate the q-value Q(s,a). \n",
    "\n",
    "### Agents\n",
    "We implement a ddpg agent (ddpg/agent.py) which use two networks (actor and critic) to learn the optimal policy. \n",
    "At every time step, all 20 agents collect experiences and add them to one shared memory buffer. After every 20 time-steps, we then let the agent do the network update 10 times (from 10 different sample from the memory buffer). To prevent gradient explosion, we use gradient clipping on the critic network. We also turn off the noise parameters. \n",
    "\n",
    "The hyper-paremeters are as followed:\n",
    "\n",
    "- BUFFER_SIZE = int(1e6)\n",
    "- BATCH_SIZE = 512\n",
    "- GAMMA = 0.99 # the discount factor\n",
    "- TAU = 1e-3       # the soft-update parameter\n",
    "- LR_ACTOR = 1e-3  # the learning rate of the actor \n",
    "- LR_CRITIC = 1e-3 # the learning rate of the critic  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-25T03:54:19.349887Z",
     "start_time": "2019-10-25T03:54:19.337885Z"
    }
   },
   "outputs": [],
   "source": [
    "def run_episode(env, brain_name, agent, max_t=1000, update_freq=20, num_updates=10):\n",
    "    env_info = env.reset(train_mode=True)[brain_name]     # reset the environment\n",
    "    states   = env_info.vector_observations               # get the current state (for each agent)\n",
    "    agent.reset()\n",
    "\n",
    "    num_agents = len(env_info.agents)\n",
    "    scores = np.zeros(num_agents)                          # initialize the score (for each agent)\n",
    "    for t in range(max_t):\n",
    "        actions     = agent.act(states, add_noise=False)\n",
    "        env_info    = env.step(actions)[brain_name] \n",
    "        \n",
    "        next_states = env_info.vector_observations         # get next state (for each agent)\n",
    "        rewards     = env_info.rewards                     # get reward (for each agent)\n",
    "        dones       = env_info.local_done                  # see if episode finished\n",
    "\n",
    "        for state, action, reward, next_state, done in zip(states, actions, rewards, next_states, dones):\n",
    "            agent.add_experience(state, action, reward, next_state, done)\n",
    "                \n",
    "        if (t % update_freq) == 0:\n",
    "            for i in range(num_updates):\n",
    "                agent.learn()\n",
    "        \n",
    "        states  = next_states                               # roll over states to next time step\n",
    "        scores += rewards\n",
    "        if np.any(dones):\n",
    "            break \n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-25T03:54:23.987939Z",
     "start_time": "2019-10-25T03:54:21.081906Z"
    }
   },
   "outputs": [],
   "source": [
    "agent = Agent(state_size=state_size, action_size=action_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-25T06:11:10.066466Z",
     "start_time": "2019-10-25T03:54:23.991939Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: Episode Score: [0.45]\tAvg Score: [0.45]\n",
      "2: Episode Score: [0.60]\tAvg Score: [0.48]\n",
      "4: Episode Score: [0.57]\tAvg Score: [0.53]\n",
      "6: Episode Score: [1.18]\tAvg Score: [0.67]\n",
      "8: Episode Score: [1.51]\tAvg Score: [0.81]\n",
      "10: Episode Score: [2.79]\tAvg Score: [1.10]\n",
      "12: Episode Score: [2.81]\tAvg Score: [1.37]\n",
      "14: Episode Score: [3.77]\tAvg Score: [1.66]\n",
      "16: Episode Score: [6.65]\tAvg Score: [2.15]\n",
      "18: Episode Score: [14.57]\tAvg Score: [3.14]\n",
      "20: Episode Score: [21.18]\tAvg Score: [4.52]\n",
      "22: Episode Score: [30.06]\tAvg Score: [6.56]\n",
      "24: Episode Score: [32.46]\tAvg Score: [8.57]\n",
      "26: Episode Score: [35.65]\tAvg Score: [10.55]\n",
      "28: Episode Score: [35.82]\tAvg Score: [12.32]\n",
      "30: Episode Score: [36.67]\tAvg Score: [13.83]\n",
      "32: Episode Score: [39.25]\tAvg Score: [15.34]\n",
      "34: Episode Score: [39.22]\tAvg Score: [16.69]\n",
      "36: Episode Score: [39.24]\tAvg Score: [17.90]\n",
      "38: Episode Score: [39.31]\tAvg Score: [19.00]\n",
      "40: Episode Score: [39.52]\tAvg Score: [20.00]\n",
      "42: Episode Score: [39.49]\tAvg Score: [20.90]\n",
      "44: Episode Score: [39.46]\tAvg Score: [21.72]\n",
      "46: Episode Score: [39.37]\tAvg Score: [22.47]\n",
      "48: Episode Score: [39.33]\tAvg Score: [23.16]\n",
      "50: Episode Score: [39.38]\tAvg Score: [23.80]\n",
      "52: Episode Score: [39.44]\tAvg Score: [24.38]\n",
      "54: Episode Score: [39.30]\tAvg Score: [24.93]\n",
      "56: Episode Score: [39.21]\tAvg Score: [25.43]\n",
      "58: Episode Score: [39.18]\tAvg Score: [25.90]\n",
      "60: Episode Score: [39.39]\tAvg Score: [26.33]\n",
      "62: Episode Score: [39.42]\tAvg Score: [26.74]\n",
      "64: Episode Score: [39.32]\tAvg Score: [27.12]\n",
      "66: Episode Score: [39.20]\tAvg Score: [27.48]\n",
      "68: Episode Score: [38.53]\tAvg Score: [27.80]\n",
      "70: Episode Score: [38.85]\tAvg Score: [28.11]\n",
      "72: Episode Score: [35.58]\tAvg Score: [28.35]\n",
      "74: Episode Score: [31.86]\tAvg Score: [28.45]\n",
      "76: Episode Score: [32.57]\tAvg Score: [28.52]\n",
      "78: Episode Score: [37.34]\tAvg Score: [28.70]\n",
      "80: Episode Score: [36.41]\tAvg Score: [28.91]\n",
      "82: Episode Score: [35.03]\tAvg Score: [29.05]\n",
      "84: Episode Score: [38.04]\tAvg Score: [29.23]\n",
      "86: Episode Score: [35.62]\tAvg Score: [29.39]\n",
      "88: Episode Score: [37.34]\tAvg Score: [29.57]\n",
      "90: Episode Score: [37.74]\tAvg Score: [29.74]\n",
      "92: Episode Score: [38.33]\tAvg Score: [29.93]\n",
      "94: Episode Score: [38.84]\tAvg Score: [30.12]\n",
      "96: Episode Score: [38.28]\tAvg Score: [30.29]\n",
      "98: Episode Score: [38.72]\tAvg Score: [30.46]\n",
      "100: Episode Score: [38.58]\tAvg Score: [30.91]\n",
      "102: Episode Score: [38.50]\tAvg Score: [31.66]\n",
      "104: Episode Score: [38.14]\tAvg Score: [32.41]\n",
      "106: Episode Score: [37.75]\tAvg Score: [33.15]\n",
      "108: Episode Score: [37.98]\tAvg Score: [33.87]\n",
      "110: Episode Score: [37.79]\tAvg Score: [34.57]\n",
      "112: Episode Score: [38.42]\tAvg Score: [35.28]\n",
      "114: Episode Score: [37.99]\tAvg Score: [35.98]\n",
      "116: Episode Score: [38.60]\tAvg Score: [36.63]\n",
      "118: Episode Score: [38.68]\tAvg Score: [37.18]\n",
      "120: Episode Score: [39.00]\tAvg Score: [37.60]\n",
      "122: Episode Score: [38.88]\tAvg Score: [37.81]\n",
      "124: Episode Score: [38.75]\tAvg Score: [37.94]\n",
      "126: Episode Score: [38.82]\tAvg Score: [38.02]\n",
      "128: Episode Score: [39.05]\tAvg Score: [38.08]\n",
      "130: Episode Score: [39.26]\tAvg Score: [38.14]\n",
      "132: Episode Score: [39.30]\tAvg Score: [38.15]\n",
      "134: Episode Score: [39.36]\tAvg Score: [38.16]\n",
      "136: Episode Score: [39.06]\tAvg Score: [38.16]\n",
      "138: Episode Score: [38.57]\tAvg Score: [38.14]\n",
      "140: Episode Score: [38.38]\tAvg Score: [38.13]\n",
      "142: Episode Score: [38.66]\tAvg Score: [38.11]\n",
      "144: Episode Score: [38.75]\tAvg Score: [38.10]\n",
      "146: Episode Score: [38.72]\tAvg Score: [38.09]\n",
      "148: Episode Score: [38.38]\tAvg Score: [38.07]\n",
      "150: Episode Score: [38.23]\tAvg Score: [38.05]\n",
      "152: Episode Score: [38.12]\tAvg Score: [38.03]\n",
      "154: Episode Score: [36.52]\tAvg Score: [37.98]\n",
      "156: Episode Score: [35.57]\tAvg Score: [37.91]\n",
      "158: Episode Score: [36.61]\tAvg Score: [37.87]\n",
      "160: Episode Score: [38.52]\tAvg Score: [37.85]\n",
      "162: Episode Score: [38.84]\tAvg Score: [37.84]\n",
      "164: Episode Score: [38.22]\tAvg Score: [37.82]\n",
      "166: Episode Score: [36.53]\tAvg Score: [37.78]\n",
      "168: Episode Score: [35.36]\tAvg Score: [37.72]\n",
      "170: Episode Score: [37.15]\tAvg Score: [37.67]\n",
      "172: Episode Score: [37.50]\tAvg Score: [37.68]\n",
      "174: Episode Score: [38.05]\tAvg Score: [37.79]\n",
      "176: Episode Score: [36.75]\tAvg Score: [37.91]\n",
      "178: Episode Score: [36.83]\tAvg Score: [37.95]\n",
      "180: Episode Score: [38.43]\tAvg Score: [37.97]\n",
      "182: Episode Score: [37.18]\tAvg Score: [38.03]\n",
      "186: Episode Score: [36.23]\tAvg Score: [38.06]\n",
      "188: Episode Score: [37.44]\tAvg Score: [38.06]\n",
      "190: Episode Score: [37.50]\tAvg Score: [38.06]\n",
      "192: Episode Score: [37.35]\tAvg Score: [38.05]\n",
      "194: Episode Score: [37.92]\tAvg Score: [38.03]\n",
      "196: Episode Score: [38.33]\tAvg Score: [38.03]\n",
      "198: Episode Score: [37.61]\tAvg Score: [38.00]\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "for i in range(200):\n",
    "    all_agent_scores = run_episode(env, brain_name, agent)\n",
    "    epi_score = np.mean(all_agent_scores)\n",
    "    scores += [epi_score]\n",
    "    \n",
    "    if (i % 2) == 0:\n",
    "        print('\\r%d: Episode Score: [%.2f]\\tAvg Score: [%.2f]' % (i, epi_score, np.mean(scores[-100:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-25T06:50:51.222863Z",
     "start_time": "2019-10-25T06:50:51.200863Z"
    }
   },
   "outputs": [],
   "source": [
    "# save parameters\n",
    "agent.save_model('model/actor.pt', 'model/critic.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-25T07:36:18.554947Z",
     "start_time": "2019-10-25T07:36:18.549947Z"
    }
   },
   "source": [
    "## Training Performance\n",
    "\n",
    "Our agent can solve the environment after 23 episodes (the average scores of 20 agents is 30+). And the performance of the agent remain above 30+ from the 22th episode onward (upto the 200th episode)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-25T07:33:04.685253Z",
     "start_time": "2019-10-25T07:33:03.818231Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x29336fef630>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot rewards score over 200 episodes\n",
    "plt.plot(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-25T06:53:02.371628Z",
     "start_time": "2019-10-25T06:53:02.364624Z"
    }
   },
   "outputs": [],
   "source": [
    "agent.load_model('model/actor.pt', 'model/critic.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-25T07:41:23.110447Z",
     "start_time": "2019-10-25T07:41:23.104445Z"
    }
   },
   "outputs": [],
   "source": [
    "def play_episode(env, brain_name, agent):\n",
    "    env_info = env.reset(train_mode=False)[brain_name]     # reset the environment\n",
    "    states   = env_info.vector_observations               # get the current state (for each agent)\n",
    "\n",
    "    num_agents = len(env_info.agents)\n",
    "    while True:\n",
    "        actions     = agent.act(states, add_noise=False)\n",
    "        env_info    = env.step(actions)[brain_name] \n",
    "        \n",
    "        next_states = env_info.vector_observations         # get next state (for each agent)\n",
    "        rewards     = env_info.rewards                     # get reward (for each agent)\n",
    "        dones       = env_info.local_done                  # see if episode finished\n",
    "\n",
    "        states  = next_states                               # roll over states to next time step\n",
    "        if np.any(dones):\n",
    "            break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "play_episode(env, brain_name, agent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Idea for Improvement\n",
    "\n",
    "- try implementing PPO instead of DDPG for the agent\n",
    "- use priroitized memory buffer (from project 1) instead of the vanilla buffer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
